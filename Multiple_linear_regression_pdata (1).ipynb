{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7fCTqNGFEmWx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "d83il-E-E9P2"
   },
   "outputs": [],
   "source": [
    "file_path = 'Inputs_modified.xlsx'\n",
    "dataset=pd.read_excel(file_path)\n",
    "x=dataset.iloc[2:,2:-1].values\n",
    "y=dataset.iloc[2:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9WwnyTqvG3we",
    "outputId": "660aebf9-4002-4846-a293-576eeb7f0087",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52.6 76.6 19.2 ... 0 600 2]\n",
      " [52.6 76.6 19.2 ... 0 600 2.3]\n",
      " [52.6 76.6 19.2 ... 0 900 1.8]\n",
      " ...\n",
      " [38.1 66 13.6 ... 0.2388 1500 1.8]\n",
      " [38.1 66 13.6 ... 0.2388 1500 2]\n",
      " [38.1 66 13.6 ... 0.2388 1500 2.3]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FD0lY7EMHx18",
    "outputId": "d8298ce9-f332-4351-d1c8-bd163be2990b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.4900692 44.0212568 103.090293 98.0306171 92.0327738 120.695862\n",
      " 117.973042 114.246795 137.594684 137.103579 135.643063 119.083949\n",
      " 113.581613 107.325081 223.451568 215.423479 205.202528 256.163744\n",
      " 252.699618 247.067974 287.612614 288.357209 287.151583 54.5844441\n",
      " 47.6059779 40.1867174 146.405566 133.971542 120.409132 182.754255\n",
      " 174.44631 164.795386 217.872122 213.737578 208.129133 171.557512\n",
      " 168.832244 164.470379 280.128094 277.743054 272.585691 309.384675\n",
      " 310.907001 310.20901 338.032976 342.998919 346.221891 69.4333031\n",
      " 65.407838 60.9394313 140.059377 133.864298 126.318114 162.394769\n",
      " 159.285135 154.779523 183.880081 183.676551 182.167157 40.0930395\n",
      " 32.8929284 25.2785053 129.029184 115.98735 101.964396 165.852115\n",
      " 156.800686 146.568687 201.55345 196.573817 190.265646 25.7707222\n",
      " 18.6693525 11.1905385 105.637114 92.5380291 78.644788 142.324015\n",
      " 132.897781 122.514736 177.990661 172.341626 165.588549 37.5444388\n",
      " 35.0107133 32.2489806 77.5150042 73.2956993 68.4072638 91.7893871\n",
      " 89.3855542 86.2410137 105.464679 104.822267 103.441784 34.660393\n",
      " 31.5628256 28.2270584 81.745434 76.4721642 70.4958423 98.1588502\n",
      " 94.9503507 90.9434057 113.949136 112.773032 110.775566 120.131887\n",
      " 114.750256 108.575248 226.78835 219.22244 209.357918 258.71213 255.691912\n",
      " 250.451343 289.471344 290.60976 289.783426 41.06432 33.0562122 24.6620062\n",
      " 61.7411681 55.75979 49.3295577 82.0167363 78.1044857 73.6832886 89.105613\n",
      " 82.7712139 75.8897166 187.159551 176.569331 164.382343 222.258479\n",
      " 216.107539 208.178475 255.935806 254.109736 250.498069 71.8798731\n",
      " 65.48975 58.6333301 162.874704 151.668 139.188629 198.273513 191.207332\n",
      " 182.65337 232.259248 229.330898 224.823173 89.9585487 83.4646803\n",
      " 76.4292284 188.443435 177.397219 164.802728 225.107137 218.561667\n",
      " 210.264511 260.240894 258.114711 254.204202 29.4946876 22.0061827\n",
      " 14.1132885 116.725079 102.932516 88.2598906 155.363345 145.513322\n",
      " 134.599385 192.89526 187.095923 180.072041 106.856073 100.674633\n",
      " 93.8223432 214.504981 204.895265 193.248016 249.189531 244.316575\n",
      " 237.322116 282.505298 282.102055 279.700374 84.3057514 77.8213933\n",
      " 70.7989898 183.731155 172.858168 160.40702 218.824055 212.404501\n",
      " 204.219693 252.546856 250.477629 246.622992 56.7216437 53.2014247\n",
      " 49.343001 113.653219 107.907488 101.165725 133.643702 130.482295\n",
      " 126.239167 152.802692 152.125962 150.390953 83.3017218 77.4639798\n",
      " 71.1217494 173.676262 163.839586 152.539317 206.600921 200.878017\n",
      " 193.515704 238.141569 236.434472 233.073567 93.2355876 86.8453028\n",
      " 79.8900198 193.475026 182.832284 170.533621 229.259754 223.154376\n",
      " 215.213133 263.567588 261.869503 258.336833 134.987545 129.930059\n",
      " 123.996174 238.651989 231.668368 222.327352 271.139214 268.688257\n",
      " 264.002838 302.408825 304.065306 303.780146 50.9398213 46.1908476\n",
      " 41.1067295 117.017904 108.638951 99.3641941 143.226375 137.863419\n",
      " 131.445632 168.410629 166.074797 162.607543 110.846549 105.088383\n",
      " 98.6450947 213.797349 205.014769 194.196236 247.122796 242.902041\n",
      " 236.598869 279.118963 279.166532 277.285736 110.185037 104.206824\n",
      " 97.5645064 213.714301 204.33623 192.984384 248.44263 243.714498\n",
      " 236.921995 281.726104 281.388851 279.105685 242.951884 254.598005\n",
      " 261.768473 357.402978 362.749149 366.10086 388.376184 395.756944\n",
      " 401.775398 418.753733 428.298665 436.789023 72.2838873 65.7482165\n",
      " 58.7446198 163.485678 151.989226 139.236725 199.608807 192.291779\n",
      " 183.500211 234.315926 231.189335 226.490066 77.5750059 70.9359285\n",
      " 63.807184 171.265195 159.608876 146.629359 208.40248 201.063526\n",
      " 192.176408 244.041376 241.022484 236.362441 57.1057396 51.7292897\n",
      " 45.9663442 133.102516 123.733215 113.302594 161.997986 156.065675\n",
      " 148.898079 189.801348 187.29848 183.487636 32.1597258 27.6869427\n",
      " 22.9464478 87.0976975 78.9678142 70.2102987 111.119563 105.528513\n",
      " 99.1790648 134.335424 131.344405 127.500152 61.5390932 55.1673831\n",
      " 48.3431843 155.243533 144.144154 131.751636 188.890709 181.87977\n",
      " 173.366842 221.278348 218.337749 213.808985 22.1861716 14.3703955\n",
      " 6.15035839 108.6543 94.3302634 79.1613466 147.674115 137.313404\n",
      " 125.942326 185.709263 179.411665 171.957654 35.1425672 27.8965765\n",
      " 20.2649023 112.460638 99.1274495 85.0097921 151.023604 141.423265\n",
      " 130.879773 188.516799 182.781336 175.969614 44.2105264 36.972806\n",
      " 29.3207295 130.462033 117.235871 103.073153 168.96158 159.715678\n",
      " 149.336001 206.243295 201.085456 194.63993 53.2333091 46.4826342\n",
      " 39.3130266 139.02462 126.826388 113.607059 175.339491 167.079003\n",
      " 157.589337 210.392645 206.151997 200.546428 39.3421254 32.0202017\n",
      " 24.2898121 124.837838 111.514921 97.2811761 162.747851 153.36751\n",
      " 142.88996 199.541603 194.200449 187.61312 58.6840748 51.9867039\n",
      " 44.8597129 144.779988 132.751982 119.660305 181.066859 173.02169\n",
      " 163.701809 216.047131 212.047979 206.638749 55.7061578 48.6117633\n",
      " 41.0767343 146.062324 133.279007 119.416551 183.966135 175.320837\n",
      " 165.37918 220.561224 216.13012 210.258835 51.6659738 44.914809 37.7475816\n",
      " 137.164486 124.998118 111.816446 173.037546 164.7869 155.316244\n",
      " 207.687767 203.425819 197.806561 247.357653 240.292179 232.81267\n",
      " 340.204298 327.656277 314.065883 377.255276 368.771134 359.029788\n",
      " 413.083979 408.736237 402.984781 50.9724933 44.1807307 36.9762405\n",
      " 135.834233 123.562772 110.301487 172.086329 163.715925 154.153887\n",
      " 207.115876 202.726578 197.005852 39.1177908 31.7477501 23.9673878\n",
      " 123.052656 109.577352 95.2111738 161.580875 152.042072 141.428886\n",
      " 198.968286 193.474209 186.754611 39.4179034 32.860946 25.9268966\n",
      " 119.61819 107.823637 95.1329816 152.955471 144.793288 135.556533\n",
      " 185.30337 180.844238 175.185286 34.5454599 27.2251284 19.5030697\n",
      " 118.510672 105.078528 90.7763227 156.658261 147.108324 136.508077\n",
      " 193.693373 188.135735 181.377187 52.0187266 44.9859809 37.5323826\n",
      " 137.234778 124.455059 110.701106 175.207607 166.408317 156.432037\n",
      " 211.909257 207.188186 201.141811 32.0520992 16.6256354 69.6214875\n",
      " 57.740264 45.1868228 106.689837 98.4097233 89.411393 65.1693977\n",
      " 51.2052031 36.6021016 101.618327 91.1069012 79.8582708 137.401175\n",
      " 130.460405 122.714368 39.0113152 31.9194118 24.4275461 122.87272\n",
      " 109.940767 96.108011 159.831589 150.75295 140.587303 195.676965\n",
      " 190.553026 184.198794 72.556784 65.6829373 58.3276085 167.007606\n",
      " 154.956151 141.619395 204.205633 196.476519 187.240228 240.011371\n",
      " 236.614484 231.60607 75.8015429 69.0586153 61.8265134 170.652282\n",
      " 158.872419 145.763166 207.613087 200.170248 191.17593 243.133833\n",
      " 240.021994 235.263393 53.0790868 45.7624249 37.9892601 149.464599\n",
      " 136.342397 122.057952 187.544256 178.720905 168.507958 224.329225\n",
      " 219.86231 213.858588 37.6504238 22.8365023 7.43972207 76.0949717\n",
      " 64.6711163 52.603264 113.964735 106.055468 97.4667352 158.132176\n",
      " 153.294776 147.489838 256.505233 249.649814 240.422773 291.172186\n",
      " 288.929171 284.44228 324.456806 326.379167 326.36393 91.0131103\n",
      " 84.8787401 78.1703573 191.280214 181.457127 169.884159 224.24754\n",
      " 218.837245 211.549304 255.977371 254.794437 251.785857 129.62932\n",
      " 124.070447 117.770457 227.809729 219.292928 208.72683 262.615072\n",
      " 258.698729 252.696691 295.946534 296.316569 294.771835 75.1447873\n",
      " 68.4619632 61.2762741 174.744232 163.259057 150.322571 210.666245\n",
      " 203.593079 194.854726 245.198155 242.487828 238.044804 130.407381\n",
      " 124.285016 117.539583 217.678058 207.216312 195.174678 257.279917\n",
      " 251.388802 243.725461 295.081722 293.665442 290.476047 80.7848542\n",
      " 74.0918387 66.8969812 176.672717 165.062306 152.067975 213.726307\n",
      " 206.505098 197.680386 249.310148 246.455816 241.919081 123.052314\n",
      " 117.328395 110.860175 227.581216 219.004416 208.279974 261.880061\n",
      " 257.979451 251.917184 294.806567 295.248228 293.718174 127.103243\n",
      " 122.396789 116.725779 235.467027 229.851608 221.679233 264.317944\n",
      " 262.94273 259.305646 292.366495 294.815136 295.364374 53.9046554\n",
      " 49.3127166 44.3779809 119.270425 111.365203 102.510964 144.088565\n",
      " 139.167305 133.153438 167.971585 166.013301 162.914733 87.8358222\n",
      " 81.6187988 74.8783573 181.654324 171.22808 159.296031 216.041711\n",
      " 209.90824 202.087763 249.065307 247.130103 243.491943 12.4643444\n",
      " 2.30375506 0 26.3078738 16.5691551 6.2998618 100.808168 94.6007169\n",
      " 87.8066802 199.389087 189.14443 177.196651 235.089215 229.379152\n",
      " 221.80155 269.278667 267.950784 264.784502 72.0465307 67.5384145\n",
      " 62.6221696 141.045447 133.476645 124.753089 167.210396 162.872211\n",
      " 157.246183 192.253219 191.062886 188.582838 47.3024123 32.7054396\n",
      " 17.4992239 84.1791317 73.044474 61.2261457 120.465554 112.852891\n",
      " 104.485971 24.7942722 17.0895893 8.99350422 100.073694 85.8013208\n",
      " 70.7950056 140.921329 130.421218 119.052645 180.736875 174.138724\n",
      " 166.541559 64.373427 57.720862 50.6180612 154.064157 142.223101\n",
      " 129.210837 190.279344 182.545969 173.421513 225.130643 221.545913\n",
      " 216.451068 51.0129702 44.0593348 36.675364 142.524255 130.032353\n",
      " 116.449583 178.996084 170.581118 160.858808 214.222942 209.944732\n",
      " 204.217103 126.428908 122.860055 118.34801 215.264984 211.02923\n",
      " 204.604744 241.093112 240.48801 237.963632 266.138887 268.751219\n",
      " 269.781467 86.0295135 83.6043688 80.5348374 146.65583 143.79629\n",
      " 139.444484 164.182395 163.788049 162.088176 181.186567 182.9772\n",
      " 183.692632 76.0980658 69.3035185 62.0191166 170.912941 159.01806\n",
      " 145.800245 208.18156 200.639495 191.549647 244.002816 240.816006\n",
      " 235.984018 72.4680613 58.1368073 43.0574047 105.490023 94.881358\n",
      " 83.4133284 138.159622 131.289235 123.484764 99.3142896 92.4165408\n",
      " 84.8935651 206.510866 195.911258 183.357695 240.321946 234.372521\n",
      " 226.41609 273.189896 271.724079 268.326925 113.396283 107.766941\n",
      " 101.385297 218.167537 210.148506 199.903596 249.387055 245.859516\n",
      " 240.160908 279.582594 280.209767 278.890532 57.1980608 49.783011\n",
      " 41.9021354 124.887028 111.300468 96.7015223 158.689693 149.05531\n",
      " 138.150498 191.369237 185.863312 178.843946 42.2305619 36.2783329\n",
      " 29.9618589 118.693259 108.002589 96.4068984 149.644959 142.398004\n",
      " 134.067057 179.573213 175.824923 170.874127 73.5684156 68.4730961\n",
      " 62.9240493 172.40264 164.211847 154.688748 203.627728 199.123894\n",
      " 193.228421 233.730075 232.752042 230.439229 17.0370557 10.9982329\n",
      " 4.65812162 100.127855 89.0536209 77.3269801 136.024658 128.184882\n",
      " 119.578539 170.93279 166.390958 160.99919 71.8753593 65.8514198\n",
      " 59.3669308 158.987029 148.655231 137.030401 191.527882 185.16215\n",
      " 177.314467 222.818112 220.376505 216.394528 81.1466559 74.9821523\n",
      " 68.3101602 174.687108 164.253932 152.354279 208.622771 202.419404\n",
      " 194.562251 241.191025 239.133527 235.390648 101.62302 95.5107715\n",
      " 88.805024 197.666734 187.678588 175.988309 232.423647 226.89647\n",
      " 219.518801 265.7585 264.527417 261.483081 195.483167 194.333362\n",
      " 190.766833 295.672258 306.853934 304.284946 327.522785 339.726637\n",
      " 340.545843 356.966863 371.236606 375.793338 17.8865325 9.85391218\n",
      " 1.41891048 101.562476 87.0936346 71.8010685 139.34823 128.826424\n",
      " 117.338623 176.353693 169.850334 162.265296 47.8860983 38.0714492\n",
      " 27.784617 72.5724385 65.2341004 57.3485701 96.825749 92.0124502 86.588055]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UZGUXaDkpOYV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.8,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62zpq1hGOt9R",
    "outputId": "3fe4c3ca-4f3e-415b-9e04-87ae67e90974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is: (783, 11)\n",
      "The shape of y_train is:  (783,)\n",
      "Number of training examples (m): 783\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of x_train is:', x_train.shape)\n",
    "print ('The shape of y_train is: ', y_train.shape)\n",
    "print ('Number of training examples (m):', len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-nyq2ggUWlT",
    "outputId": "786d2adb-3c0e-4249-cfcc-bd3a05752b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train is numpy array: True\n",
      "y_train is numpy array: True\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train is numpy array: {isinstance(x_train, np.ndarray)}')\n",
    "print(f'y_train is numpy array: {isinstance(y_train, np.ndarray)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "awOY78z5JVLG"
   },
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes the cost function for linear regression with eleven variables using a for loop.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): Shape (m, 11) Input to the model (four features of the training examples)\n",
    "        y (ndarray): Shape (m,) Label (Actual output values for the training examples)\n",
    "        w (ndarray): Shape (11,) Parameters of the model (weights for the four features)\n",
    "        b (scalar): Parameter of the model (bias)\n",
    "\n",
    "    Returns:\n",
    "        total_cost (float): The cost of using w, b as the parameters for linear regression\n",
    "                            to fit the data points in x and y.\n",
    "    \"\"\"\n",
    "    # Number of training examples\n",
    "    m = x.shape[0]\n",
    "\n",
    "    # Initialize total cost\n",
    "    total_cost = 0\n",
    "\n",
    "    # Compute the total cost using a for loop\n",
    "    for i in range(m):\n",
    "        f_wb_i = b  # Start with the bias term\n",
    "        for j in range(11):  # Sum over all features\n",
    "            f_wb_i += w[j] * x[i, j]\n",
    "        total_cost += (f_wb_i - y[i]) ** 2  # Sum of squared errors\n",
    "\n",
    "    # Compute the average cost\n",
    "    total_cost = total_cost / (2 * m)\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZN0kJQKcKDo6",
    "outputId": "dc4dd754-91db-409c-b0cd-890bfad7333e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "Cost at initial w: 31677.978\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.array([0.1, 0.02, 0.01, 0.05, 0.3, 0.03, 0.02, 0.01, 0.04, 0.35, 0.15])\n",
    "initial_b =0.5\n",
    "\n",
    "cost = compute_cost(x_train, y_train, initial_w, initial_b)\n",
    "print(type(cost))\n",
    "print(f'Cost at initial w: {cost:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "S0CitG7CcG5a"
   },
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression with multiple variables.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): Shape (m, n) Input to the model (features of the training examples)\n",
    "        y (ndarray): Shape (m,) Label (actual output values for the training examples)\n",
    "        w (ndarray): Shape (n,) Parameters of the model (weights for the features)\n",
    "        b (scalar): Parameter of the model (bias)\n",
    "\n",
    "    Returns:\n",
    "        dj_dw (ndarray): Shape (n,) The gradient of the cost w.r.t. the parameters w\n",
    "        dj_db (scalar): The gradient of the cost w.r.t. the parameter b\n",
    "    \"\"\"\n",
    "    # Number of training examples\n",
    "    m, n = x.shape\n",
    "\n",
    "    # Initialize gradients\n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0.0\n",
    "\n",
    "    # Compute the gradients\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b  # Predicted value\n",
    "        error = f_wb_i - y[i]  # Error term\n",
    "        for j in range(n):\n",
    "            dj_dw[j] += error * x[i, j]  # Gradient for w[j]\n",
    "        dj_db += error  # Gradient for b\n",
    "\n",
    "    # Average the gradients\n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "\n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9uvMegwcsWN",
    "outputId": "0389aa4c-ad09-4817-e40a-2bd6dae046a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient at initial w, b (zeros): [3.82163783e+03 1.78270106e+04 4.12352577e+03 1.42791536e+03\n",
      " 1.11713497e+04 9.17539535e+03 1.35747851e+03 2.13240954e+02\n",
      " 3.20255291e+01 2.70312287e+05 4.75490238e+02] 233.7740538862323\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.array([0.1, 0.02, 0.01, 0.05, 0.3, 0.03, 0.02, 0.01, 0.04, 0.35, 0.15])\n",
    "initial_b = 0\n",
    "\n",
    "tmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, initial_w, initial_b)\n",
    "print('Gradient at initial w, b (zeros):', tmp_dj_dw, tmp_dj_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "mLUdICAjA2to"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking\n",
    "    num_iters gradient steps with learning rate alpha.\n",
    "\n",
    "    Args:\n",
    "        x : (ndarray): Shape (m, n) Input data (features of the training examples).\n",
    "        y : (ndarray): Shape (m,) Output data (actual output values for the training examples).\n",
    "        w_in : (ndarray): Shape (n,) Initial values of parameters (weights) of the model.\n",
    "        b_in : (scalar) Initial value of parameter (bias) of the model.\n",
    "        cost_function : function to compute cost.\n",
    "        gradient_function : function to compute the gradient.\n",
    "        alpha : (float) Learning rate.\n",
    "        num_iters : (int) Number of iterations to run gradient descent.\n",
    "\n",
    "    Returns:\n",
    "        w : (ndarray): Shape (n,) Updated values of parameters (weights) of the model after running gradient descent.\n",
    "        b : (scalar) Updated value of parameter (bias) of the model after running gradient descent.\n",
    "        J_history : List of costs at each iteration.\n",
    "        w_history : List of weights at each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize parameters\n",
    "    w = copy.deepcopy(w_in)  # Avoid modifying global w within function\n",
    "    b = b_in\n",
    "\n",
    "    # History of cost and weights\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_dw, dj_db = gradient_function(x, y, w, b)\n",
    "\n",
    "        # Update Parameters using w, b, alpha, and gradient\n",
    "        for j in range(11):\n",
    "          w[j] = w[j] - alpha * dj_dw[j]\n",
    "          b = b - alpha * dj_db\n",
    "\n",
    "        # Save cost J at each iteration\n",
    "        if i < 1000000:  # Prevent resource exhaustion\n",
    "            cost = cost_function(x, y, w, b)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i % math.ceil(num_iters / 100) == 0:\n",
    "            w_history.append(w.copy())\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}\")\n",
    "\n",
    "    return w, b, J_history, w_history  # Return w and J, w history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ns8IIXupA8XK",
    "outputId": "65fd9fdb-2696-4b07-b91b-f20ffe08e213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost  2898.18\n",
      "Iteration 4000: Cost  1785.38\n",
      "Iteration 8000: Cost  1597.98\n",
      "Iteration 12000: Cost  1471.99\n",
      "Iteration 16000: Cost  1370.06\n",
      "Iteration 20000: Cost  1282.10\n",
      "Iteration 24000: Cost  1204.67\n",
      "Iteration 28000: Cost  1136.06\n",
      "Iteration 32000: Cost  1075.09\n",
      "Iteration 36000: Cost  1020.83\n",
      "Iteration 40000: Cost   972.47\n",
      "Iteration 44000: Cost   929.32\n",
      "Iteration 48000: Cost   890.79\n",
      "Iteration 52000: Cost   856.34\n",
      "Iteration 56000: Cost   825.51\n",
      "Iteration 60000: Cost   797.91\n",
      "Iteration 64000: Cost   773.17\n",
      "Iteration 68000: Cost   750.98\n",
      "Iteration 72000: Cost   731.07\n",
      "Iteration 76000: Cost   713.18\n",
      "Iteration 80000: Cost   697.10\n",
      "Iteration 84000: Cost   682.64\n",
      "Iteration 88000: Cost   669.61\n",
      "Iteration 92000: Cost   657.88\n",
      "Iteration 96000: Cost   647.29\n",
      "Iteration 100000: Cost   637.74\n",
      "Iteration 104000: Cost   629.10\n",
      "Iteration 108000: Cost   621.29\n",
      "Iteration 112000: Cost   614.22\n",
      "Iteration 116000: Cost   607.81\n",
      "Iteration 120000: Cost   601.99\n",
      "Iteration 124000: Cost   596.69\n",
      "Iteration 128000: Cost   591.88\n",
      "Iteration 132000: Cost   587.48\n",
      "Iteration 136000: Cost   583.47\n",
      "Iteration 140000: Cost   579.80\n",
      "Iteration 144000: Cost   576.43\n",
      "Iteration 148000: Cost   573.34\n",
      "Iteration 152000: Cost   570.50\n",
      "Iteration 156000: Cost   567.87\n",
      "Iteration 160000: Cost   565.44\n",
      "Iteration 164000: Cost   563.19\n",
      "Iteration 168000: Cost   561.10\n",
      "Iteration 172000: Cost   559.16\n",
      "Iteration 176000: Cost   557.34\n",
      "Iteration 180000: Cost   555.63\n",
      "Iteration 184000: Cost   554.03\n",
      "Iteration 188000: Cost   552.53\n",
      "Iteration 192000: Cost   551.10\n",
      "Iteration 196000: Cost   549.76\n",
      "Iteration 200000: Cost   548.48\n",
      "Iteration 204000: Cost   547.26\n",
      "Iteration 208000: Cost   546.10\n",
      "Iteration 212000: Cost   544.98\n",
      "Iteration 216000: Cost   543.92\n",
      "Iteration 220000: Cost   542.89\n",
      "Iteration 224000: Cost   541.90\n",
      "Iteration 228000: Cost   540.94\n",
      "Iteration 232000: Cost   540.01\n",
      "Iteration 236000: Cost   539.11\n",
      "Iteration 240000: Cost   538.24\n",
      "Iteration 244000: Cost   537.38\n",
      "Iteration 248000: Cost   536.55\n",
      "Iteration 252000: Cost   535.74\n",
      "Iteration 256000: Cost   534.94\n",
      "Iteration 260000: Cost   534.16\n",
      "Iteration 264000: Cost   533.39\n",
      "Iteration 268000: Cost   532.64\n",
      "Iteration 272000: Cost   531.90\n",
      "Iteration 276000: Cost   531.17\n",
      "Iteration 280000: Cost   530.45\n",
      "Iteration 284000: Cost   529.74\n",
      "Iteration 288000: Cost   529.04\n",
      "Iteration 292000: Cost   528.35\n",
      "Iteration 296000: Cost   527.66\n",
      "Iteration 300000: Cost   526.98\n",
      "Iteration 304000: Cost   526.31\n",
      "Iteration 308000: Cost   525.65\n",
      "Iteration 312000: Cost   524.99\n",
      "Iteration 316000: Cost   524.34\n",
      "Iteration 320000: Cost   523.69\n",
      "Iteration 324000: Cost   523.05\n",
      "Iteration 328000: Cost   522.41\n",
      "Iteration 332000: Cost   521.77\n",
      "Iteration 336000: Cost   521.15\n",
      "Iteration 340000: Cost   520.52\n",
      "Iteration 344000: Cost   519.90\n",
      "Iteration 348000: Cost   519.29\n",
      "Iteration 352000: Cost   518.68\n",
      "Iteration 356000: Cost   518.07\n",
      "Iteration 360000: Cost   517.46\n",
      "Iteration 364000: Cost   516.86\n",
      "Iteration 368000: Cost   516.27\n",
      "Iteration 372000: Cost   515.67\n",
      "Iteration 376000: Cost   515.08\n",
      "Iteration 380000: Cost   514.49\n",
      "Iteration 384000: Cost   513.91\n",
      "Iteration 388000: Cost   513.33\n",
      "Iteration 392000: Cost   512.75\n",
      "Iteration 396000: Cost   512.18\n",
      "w, b found by gradient descent: [-2.16389177  1.16032686  0.24059376 -6.05117932  6.06828114 -9.54920571\n",
      "  5.98529764 -0.72784185 -0.38970202  0.16475554 -0.48243596] -0.5134415962274375\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "initial_w = np.array([0.0001, 0.0000002, 0.0000001, 0.00000005, 0.0003, 0.003, 0.0000002, 0.0000001, 0.0000004, 0.0035, 0.0015])  # Initial weights for 11 features\n",
    "initial_b = 0.0  # Initial bias\n",
    "\n",
    "# Define the learning rate and number of iterations\n",
    "alpha = 0.000001\n",
    "iterations = 400000\n",
    "\n",
    "# Perform gradient descent\n",
    "w, b, _, _ = gradient_descent(x_train, y_train, initial_w, initial_b, compute_cost, compute_gradient, alpha, iterations)\n",
    "\n",
    "print(\"w, b found by gradient descent:\", w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wt_tfNUsWfvA",
    "outputId": "3c69a6a4-8d6f-45d8-834b-92a73454c0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_test is: (197, 11)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of x_test is:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9MSyCWFmVCil",
    "outputId": "8193ec8b-95af-4ea4-d6ce-8a6c211215bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223.11381712311294 223.154376\n",
      "204.13758946579898 207.188186\n",
      "123.55597149164657 133.971542\n",
      "168.564937292311 219.292928\n",
      "151.68103836850293 174.687108\n",
      "52.8862034435809 57.1057396\n",
      "170.78376501148452 175.320837\n",
      "243.5566659974027 249.387055\n",
      "55.85760549714645 44.9859809\n",
      "52.01141302537183 34.5454599\n",
      "63.04747150709137 44.2105264\n",
      "176.23651011018754 166.013301\n",
      "385.4735709749581 436.789023\n",
      "230.50173215329076 247.122796\n",
      "183.63213955026367 182.545969\n",
      "195.35457318571173 223.451568\n",
      "31.558945703922983 17.0370557\n",
      "190.72659537829026 200.170248\n",
      "245.45650295801562 244.041376\n",
      "385.618301762671 428.298665\n",
      "110.9939917713529 90.9434057\n",
      "267.51474712988795 295.946534\n",
      "354.26962374136514 342.998919\n",
      "151.14794162745153 157.246183\n",
      "172.8379020268178 164.795386\n",
      "106.72701273531221 81.6187988\n",
      "153.0622766506428 137.313404\n",
      "131.40719152800085 98.6450947\n",
      "233.05880087314785 221.545913\n",
      "255.00699670396475 247.130103\n",
      "170.88025220329314 183.966135\n",
      "154.80741533472343 175.207607\n",
      "123.69884382258213 104.485971\n",
      "247.764379796747 237.963632\n",
      "223.21030431492156 229.259754\n",
      "137.75176407566013 142.324015\n",
      "170.67055065428923 154.779523\n",
      "201.88377776458432 173.366842\n",
      "152.91754586292984 125.942326\n",
      "245.21528497849405 236.362441\n",
      "139.93209172624648 163.485678\n",
      "151.43982038898136 152.354279\n",
      "252.02420402798194 249.310148\n",
      "152.1646685506084 114.750256\n",
      "198.48244926157577 211.02923\n",
      "264.378302227581 254.794437\n",
      "202.48893797352696 179.411665\n",
      "85.94846330807954 107.907488\n",
      "301.4498251946061 303.780146\n",
      "167.64363689464284 149.05531\n",
      "190.5818645905773 191.17593\n",
      "240.3159044760431 408.736237\n",
      "81.96890123154972 62.9240493\n",
      "91.72854194480897 61.8265134\n",
      "41.998615792485445 70.2102987\n",
      "149.94600670117177 142.88996\n",
      "231.96102790155115 288.929171\n",
      "244.88138130493468 183.692632\n",
      "87.40801124264485 99.3641941\n",
      "12.140669125584534 28.2270584\n",
      "-7.186827550877174 32.1597258\n",
      "42.961523143253636 57.3485701\n",
      "202.8377205283593 238.651989\n",
      "192.61194756394852 178.720905\n",
      "281.3876892244353 326.379167\n",
      "28.05301333334364 53.9046554\n",
      "212.71861087977857 197.806561\n",
      "98.2068989804123 109.940767\n",
      "167.4989061069299 138.150498\n",
      "140.9162163389841 142.398004\n",
      "80.74438904728561 77.3269801\n",
      "164.81340981007762 174.744232\n",
      "143.59315598557095 144.793288\n",
      "264.63724528427247 240.321946\n",
      "190.4393648536769 179.573213\n",
      "114.1065062135318 137.164486\n",
      "179.59771169305395 160.99919\n",
      "140.99666922596674 131.344405\n",
      "237.81839850110478 248.44263\n",
      "190.19814687415533 170.874127\n",
      "42.98892443734477 23.9673878\n",
      "192.3384391947316 219.004416\n",
      "165.1359752328627 181.066859\n",
      "237.72191130929616 243.714498\n",
      "291.04703105278696 293.718174\n",
      "151.3891596069731 167.210396\n",
      "160.76392276395026 165.852115\n",
      "-6.320407391917595 38.0714492\n",
      "138.96507585533644 110.185037\n",
      "112.20013075065297 217.678058\n",
      "156.25016125000502 181.654324\n",
      "270.94789066294663 262.94273\n",
      "111.95891277113141 195.174678\n",
      "27.811795353822074 44.3779809\n",
      "94.18140634091576 58.6333301\n",
      "264.23357143986806 251.785857\n",
      "164.89475725334114 163.701809\n",
      "279.8319062843663 279.166532\n",
      "51.092684055403424 24.2898121\n",
      "65.67339175651415 70.7950056\n",
      "92.65680373975053 123.052656\n",
      "61.8141129263733 32.8929284\n",
      "227.84019343743012 244.002816\n",
      "96.74889905078041 64.6711163\n",
      "279.68717549665337 277.285736\n",
      "31.31772772440142 4.65812162\n",
      "143.18528624106435 136.342397\n",
      "19.550697307705615 61.7411681\n",
      "215.04812809650545 224.24754\n",
      "204.1190847690243 204.219693\n",
      "267.89998550971427 267.950784\n",
      "201.0697002204248 187.29848\n",
      "94.32613712862869 65.48975\n",
      "211.94986924083742 180.072041\n",
      "96.84538624258904 76.0949717\n",
      "202.7412333365507 231.668368\n",
      "36.37707119748241 49.343001\n",
      "241.86158770942438 261.880061\n",
      "102.0131590660972 68.3101602\n",
      "205.79561439189814 202.726578\n",
      "176.1629024915012 137.594684\n",
      "105.28426682003064 124.455059\n",
      "176.54354492665274 191.527882\n",
      "111.23520975087446 98.1588502\n",
      "153.1587638424514 147.674115\n",
      "146.03082958595164 97.4667352\n",
      "217.8468678274822 252.696691\n",
      "91.96975992433053 75.8015429\n",
      "254.34963879059563 265.7585\n",
      "179.25532715372077 169.850334\n",
      "87.55274203035778 108.638951\n",
      "263.57024526403734 242.487828\n",
      "43.133655225057716 31.7477501\n",
      "170.81528144200217 159.285135\n",
      "222.26456334970197 208.129133\n",
      "190.3475283428927 182.781336\n",
      "172.98263281453075 174.44631\n",
      "200.0501790145028 181.377187\n",
      "101.96249828408894 141.045447\n",
      "202.344207185814 171.957654\n",
      "52.43934976939612 67.5384145\n",
      "204.6817594881899 219.518801\n",
      "91.58604220790858 118.693259\n",
      "131.01648954288518 116.449583\n",
      "234.671184753235 236.614484\n",
      "195.78862365560988 192.176408\n",
      "118.31346276356732 124.887028\n",
      "204.92297746771146 232.423647\n",
      "155.8808137540432 123.484764\n",
      "54.30544119668306 22.1861716\n",
      "146.50669312043865 159.608876\n",
      "165.5427046589825 84.8935651\n",
      "149.375387371723 173.676262\n",
      "154.7109281429148 166.408317\n",
      "183.48740876255073 173.421513\n",
      "143.60806766379994 139.188629\n",
      "78.05846469653999 69.6214875\n",
      "131.54029334214684 164.211847\n",
      "93.75862491818015 45.7624249\n",
      "131.5519223157138 105.088383\n",
      "66.74782665283955 12.4643444\n",
      "100.66407616600054 111.514921\n",
      "143.7527984515129 151.668\n",
      "24.990251964526724 32.7054396\n",
      "92.03592050739057 240.292179\n",
      "96.93530100984155 63.807184\n",
      "90.26421242384075 58.7446198\n",
      "180.97858363859797 205.014769\n",
      "176.30232694713118 177.314467\n",
      "126.906335979112 144.088565\n",
      "200.92496943271186 183.487636\n",
      "164.5267144022825 166.541559\n",
      "179.83892967257552 170.93279\n",
      "112.37764563816694 117.235871\n",
      "80.2572737202395 71.8010685\n",
      "126.73624116861704 120.695862\n",
      "248.00559777626856 241.093112\n",
      "153.07439419040497 165.062306\n",
      "151.29267241516447 162.872211\n",
      "143.008265063656 123.052314\n",
      "115.14553050767188 61.2762741\n",
      "242.60612109728123 229.330898\n",
      "146.2692766386879 146.65583\n",
      "191.2689084059973 186.754611\n",
      "94.02176387497384 95.1329816\n",
      "66.04143460757281 44.8597129\n",
      "91.49420569712436 99.1274495\n",
      "146.60318031224728 171.265195\n",
      "99.70750806931729 71.1217494\n",
      "42.06289369321576 36.2783329\n",
      "234.52645396552205 231.60607\n",
      "68.7903142488745 49.783011\n",
      "251.1144783881854 258.71213\n",
      "129.8286658308366 128.826424\n",
      "205.84490898499968 164.470379\n",
      "263.666732455846 245.198155\n",
      "41.91816290550282 29.9618589\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='Results_MLR.xlsx' target='_blank'>Results_MLR.xlsx</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\Mafi\\Data file\\Results_MLR.xlsx"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "k=x_test.shape[0]\n",
    "data = []\n",
    "for i in range(k):\n",
    "        f_wb_i = b  # Start with the bias term\n",
    "        for j in range(11):  # Sum over all features\n",
    "            f_wb_i += w[j] * x_test[i, j]\n",
    "        print(f_wb_i, y_test[i])\n",
    "        row= [f_wb_i, y_test[i]]\n",
    "        data.append(row)\n",
    "df = pd.DataFrame(data, columns=['Predicted', 'Actual'])\n",
    "file_name = 'Results_MLR.xlsx'\n",
    "df.to_excel(file_name, index=False)\n",
    "\n",
    "\n",
    "# Download the file\n",
    "FileLink(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
