{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fCTqNGFEmWx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d83il-E-E9P2"
   },
   "outputs": [],
   "source": [
    "file_path = 'Inputs.xlsx'\n",
    "dataset=pd.read_excel(file_path)\n",
    "x=dataset.iloc[2:,2:-1].values\n",
    "y=dataset.iloc[2:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9WwnyTqvG3we",
    "outputId": "8de19dee-be68-4c1a-cbf5-d936bbdc36de"
   },
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FD0lY7EMHx18",
    "outputId": "8a312085-2dc2-4fd8-df89-65e80e824bec"
   },
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZGUXaDkpOYV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.8,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62zpq1hGOt9R",
    "outputId": "3918b60c-e1a7-4205-ef41-f866c50332c1"
   },
   "outputs": [],
   "source": [
    "print ('The shape of x_train is:', x_train.shape)\n",
    "print ('The shape of y_train is: ', y_train.shape)\n",
    "print ('Number of training examples (m):', len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-nyq2ggUWlT",
    "outputId": "11b6ccf2-64d6-4050-c6c9-4c820c1b0525"
   },
   "outputs": [],
   "source": [
    "print(f'x_train is numpy array: {isinstance(x_train, np.ndarray)}')\n",
    "print(f'y_train is numpy array: {isinstance(y_train, np.ndarray)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awOY78z5JVLG"
   },
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, b,theta,beta):\n",
    "    \"\"\"\n",
    "    The cost function for Cubic regression with eleven variables using a for loop.\n",
    "    \"\"\"\n",
    "    # Number of training examples\n",
    "    m,n = x.shape\n",
    "\n",
    "    # Initialize total cost\n",
    "    total_cost = 0\n",
    "\n",
    "    # Compute the total cost using a for loop\n",
    "    for i in range(m):\n",
    "        f_wb_i = b  # Start with the bias term\n",
    "        for j in range(n):  # Sum over all features\n",
    "            f_wb_i += w[j] * x[i, j] + theta[j] * x[i, j]**2 + beta[j] * x[i, j]**3\n",
    "        total_cost += (f_wb_i - y[i]) ** 2  # Sum of squared errors\n",
    "\n",
    "    # Compute the average cost\n",
    "    total_cost = total_cost / (2 * m)\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZN0kJQKcKDo6",
    "outputId": "b46bb842-d8dd-418a-c344-3ba00501684a"
   },
   "outputs": [],
   "source": [
    "m,n=x_train.shape\n",
    "initial_w = np.zeros(n)\n",
    "initial_theta=np.zeros(n)\n",
    "initial_beta=np.zeros(n)\n",
    "initial_b =0.5\n",
    "\n",
    "cost = compute_cost(x_train, y_train, initial_w, initial_b,initial_theta,initial_beta)\n",
    "print(type(cost))\n",
    "print(f'Cost at initial w: {cost:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0CitG7CcG5a"
   },
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b,theta,beta):\n",
    "    \"\"\"\n",
    "    The gradient for Cubic regression with multiple variables.\n",
    "    \"\"\"\n",
    "    # Number of training examples\n",
    "    m, n = x.shape\n",
    "  \n",
    "    # Initialize gradients\n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_dtheta = np.zeros(n)\n",
    "    dj_dbeta = np.zeros(n)\n",
    "    dj_db = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + np.dot(x[i]**2,theta)+ + np.dot(x[i]**3,beta) + b  # Predicted value\n",
    "        error = f_wb_i - y[i]  # Error term\n",
    "        for j in range(n):\n",
    "            dj_dw[j] += error * x[i, j]  # Gradient for w[j]\n",
    "            dj_dtheta[j] += error * x[i, j]**2\n",
    "            dj_dbeta[j] += error * x[i, j]**3\n",
    "        dj_db += error  # Gradient for b\n",
    "\n",
    "    # Average the gradients\n",
    "    dj_dw /= m\n",
    "    dj_dtheta /= m\n",
    "    dj_dbeta /= m\n",
    "    dj_db/= m\n",
    "\n",
    "\n",
    "    return dj_dw, dj_db,dj_dtheta, dj_dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9uvMegwcsWN",
    "outputId": "6cfbb7b0-477a-456e-c796-1b2169cd8a3a"
   },
   "outputs": [],
   "source": [
    "m,n=x_train.shape\n",
    "initial_w = np.zeros(n)\n",
    "initial_theta=np.zeros(n)\n",
    "initial_beta=np.zeros(n)\n",
    "initial_b = 0\n",
    "\n",
    "tmp_dj_dw, tmp_dj_db,tmp_dj_dtheta,tmp_dj_dbeta = compute_gradient(x_train, y_train, initial_w, initial_b,initial_theta,initial_beta)\n",
    "print(f'dj_dw,dj_dtheta at initial w, b,theta (zeros): {tmp_dj_dw}')\n",
    "print('Gradient at initial w, b (zeros):', tmp_dj_dw, tmp_dj_db,tmp_dj_dtheta,tmp_dj_dbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLUdICAjA2to"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in,theta_in, beta_in, cost_function, gradient_function, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Gradient Descent.\n",
    "    \"\"\"\n",
    "    m, n = x.shape\n",
    "    # Initialize parameters\n",
    "    w = copy.deepcopy(w_in)  # Avoid modifying global w within function\n",
    "    theta=copy.deepcopy(theta_in)\n",
    "    beta=copy.deepcopy(beta_in)\n",
    "    b = b_in\n",
    "\n",
    "    # History of cost and weights\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_dw, dj_db,dj_dtheta,dj_dbeta = gradient_function(x, y, w, b,theta,beta)\n",
    "\n",
    "        # Update Parameters using w, theta, b, alpha, and gradient\n",
    "        for j in range(n):\n",
    "            w[j] = w[j] - alpha * dj_dw[j]\n",
    "            theta[j] = theta[j] - alpha * dj_dtheta[j]\n",
    "            beta[j] = beta[j] - alpha * dj_dbeta[j]\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        # Save cost J at each iteration\n",
    "        if i < 10000000:  # Prevent resource exhaustion\n",
    "            cost = cost_function(x, y, w, b,theta,beta)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i % math.ceil(num_iters / 100) == 0:\n",
    "            w_history.append(w.copy())\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):15.2f}\")\n",
    "\n",
    "    return w, b,theta,beta, J_history, w_history  # Return w and J, w history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ns8IIXupA8XK",
    "outputId": "c9c74352-2bc4-48d5-f601-1b4188d2c411"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "m,n=x_train.shape\n",
    "iinitial_w = np.array([-5.8, 2.7, 0.741, -10.8, 10.5, -12.54,8.98, -1.04, -0.75, 0.41, -0.7])\n",
    "initial_theta=np.array([0.000052, 0.000002, 0.00000004, 0.000025, 0.00008, 0.00009, 0.000041, 0.0002, 0.00012, 0.00034, 0.0000045])\n",
    "initial_beta=np.array([0.0001, 0.0000002, 0.0000001, 0.00000005, 0.0003, 0.003, 0.0000002, 0.0000001, 0.0000004, 0.0035, 0.0015])\n",
    "initial_b=-40\n",
    "\n",
    "# learning rate and number of iterations\n",
    "alpha = 0.000000000000000000000047\n",
    "iterations = 150000\n",
    "# Perform gradient descent\n",
    "w, b, theta,beta,_,_ = gradient_descent(x_train, y_train, initial_w, initial_b,initial_theta, initial_beta,compute_cost, compute_gradient, alpha, iterations)\n",
    "\n",
    "print(\"w, b found by gradient descent:\", w, b,theta,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wt_tfNUsWfvA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('The shape of x_test is:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MSyCWFmVCil"
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "k=x_test.shape[0]\n",
    "data=[]\n",
    "for i in range(k):\n",
    "        f_wb_i = b  # Start with the bias term\n",
    "        for j in range(11):  # Sum over all features\n",
    "            f_wb_i += w[j] * x_test[i, j]+theta[j] * x_test[i, j]**2 + beta[j] * x_test[i, j]**3\n",
    "        print(f_wb_i, y_test[i])\n",
    "        row= [f_wb_i,y_test[i]]\n",
    "        data.append(row)\n",
    "df=pd.DataFrame(data,columns=['Predicted','Actual'])\n",
    "file_name='Result_Cubic_Regression2.xlsx'\n",
    "df.to_excel(file_name, index=False)\n",
    "FileLink(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
